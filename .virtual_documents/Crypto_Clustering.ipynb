# Import required libraries and dependencies
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import hvplot.pandas


# Load the data into a Pandas DataFrame and make the index the "coin_id" column.
market_data_df = pd.read_csv("Resources/crypto_market_data.csv", index_col="coin_id")

# Display sample data
market_data_df.head(10)


# Generate summary statistics
market_data_df.describe()





# Create a StandardScaler instance
scaler = StandardScaler()

# Fit the scaler to the DataFrame and transform the data
market_data_scaled = scaler.fit_transform(market_data_df)


# Create a DataFrame with the scaled data
market_data_scaled_df = pd.DataFrame(market_data_scaled, columns=market_data_df.columns, index=market_data_df.index)

# Display sample data
market_data_scaled_df.head()





# Create a list with the number of k-values to try
k_values = range(1, 11)

# Create an empty list to store the inertia values
inertia = []

# Create a for loop to compute the inertia with each possible value of k
for k in k_values:
    # Create a KMeans model using the loop counter for the n_clusters
    model = KMeans(n_clusters=k, random_state=42)
    
    # Fit the model to the data using the scaled DataFrame
    model.fit(market_data_scaled_df)
    
    # Append the model.inertia_ to the inertia list
    inertia.append(model.inertia_)

# Create a dictionary with the data to plot the Elbow curve
elbow_data = {
    "k": k_values,
    "inertia": inertia
}

# Create a DataFrame with the data to plot the Elbow curve
elbow_df = pd.DataFrame(elbow_data)

# Display the DataFrame
print(elbow_df)



# Plot the elbow curve to visually determine the optimal number of clusters
plt.figure(figsize=(10, 6))  # Set the figure size to 10 by 6 inches
plt.plot(elbow_df['k'], elbow_df['inertia'], 'bo-')  # Plot the number of clusters (k) against the inertia values using blue circles and a line
plt.xlabel('Number of Clusters (k)')  # Label the x-axis as "Number of Clusters (k)"
plt.ylabel('Inertia')  # Label the y-axis as "Inertia"
plt.title('Elbow Curve')  # Set the title of the plot to "Elbow Curve"
plt.grid(True)  # Add a grid to the plot for better readability
plt.show()  # Display the plot

# Print the DataFrame containing the k values and their corresponding inertia values
print(elbow_df)








# Initialize the K-Means model using the best value for k
kmeans = KMeans(n_clusters=4, random_state=42)


# Fit the K-Means model using the scaled data
kmeans.fit(market_data_scaled_df)


# Predict the clusters to group the cryptocurrencies using the scaled data
cluster_labels = kmeans.predict(market_data_scaled_df)

# View the resulting array of cluster values.
print("Cluster Labels:", cluster_labels)


# Create a copy of the DataFrame
df_clustered = market_data_scaled_df.copy()


# Add a new column to the DataFrame with the predicted clusters
df_clustered['Cluster'] = cluster_labels

# Display sample data
display(df_clustered.head())


# Create the scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(df_clustered['price_change_percentage_24h'], 
            df_clustered['price_change_percentage_7d'], 
            c=df_clustered['Cluster'], 
            cmap='rainbow')

# Add labels and title
plt.xlabel('Price Change Percentage 24h')
plt.ylabel('Price Change Percentage 7d')
plt.title('Cryptocurrency Clusters')

# Add a color bar
plt.colorbar(label='Cluster')

# Show the plot
plt.show()





# Create a PCA model instance and set `n_components=3`.
pca = PCA(n_components=3)


# Use the PCA model with `fit_transform` on the original scaled DataFrame to reduce to three principal components.
pca_results = pca.fit_transform(market_data_scaled_df)

# View the first five rows of the DataFrame. 
print(pca_results[:5])


# Get explained variance ratio
explained_variance_ratio = pca.explained_variance_ratio_

# Print the explained variance ratio
print("Explained Variance Ratio:", explained_variance_ratio)





# Convert the results to a DataFrame
pca_df = pd.DataFrame(pca_results, columns=['PC1', 'PC2', 'PC3'])

# Set the index of pca_df to be the same as market_data_df which is coin_id
pca_df.index = market_data_df.index

# Display sample data
print(pca_df.head())





# Define a range of k values for the KMeans algorithm to test from 1 to 10 clusters
k_values = range(1, 11)

# Initialize an empty list to store the inertia values for each k
inertia = []

# Loop over each k value in the range
for k in k_values:
    # Create a KMeans model with the current number of clusters (k) and a fixed random state for reproducibility
    model = KMeans(n_clusters=k, random_state=42)
    
    # Fit the KMeans model to the PCA-transformed data (pca_df)
    model.fit(pca_df)
    
    # Append the inertia (sum of squared distances to the nearest cluster center) of the current model to the inertia list
    inertia.append(model.inertia_)

# Create a dictionary with the k values and their corresponding inertia values
pcaelbow_data = {
    "k": k_values,
    "inertia": inertia
}

# Convert the dictionary into a DataFrame to facilitate plotting the Elbow curve
pcaelbow_df = pd.DataFrame(pcaelbow_data)

# Display the DataFrame to visualize the k values and their associated inertia
display(pcaelbow_df)


# Plot the Elbow curve to evaluate the optimal number of clusters using the PCA-transformed data
plt.figure(figsize=(10, 6))  # Set the size of the figure to 10 by 6 inches for better visibility
plt.plot(pcaelbow_df['k'], pcaelbow_df['inertia'], 'bo-')  # Plot the number of clusters (k) against the inertia values with blue circles and a line
plt.xlabel('Number of Clusters (k)')  # Label the x-axis as "Number of Clusters (k)"
plt.ylabel('Inertia')  # Label the y-axis as "Inertia"
plt.title('Elbow Curve')  # Set the title of the plot to "Elbow Curve"
plt.grid(True)  # Enable grid lines on the plot for easier interpretation of the data points
plt.show()  # Display the plot to the user

# Print the DataFrame that contains the k values and their corresponding inertia values for the PCA data
print(pcaelbow_df)








# Initialize the K-Means model using the best value for k
kmeans = KMeans(n_clusters=4, random_state=42)


# Fit the K-Means model using the PCA data
kmeans.fit(pca_df)


# Predict the clusters to group the cryptocurrencies using the PCA data
pcacluster_labels = kmeans.predict(pca_df)

# View the resulting array of cluster values.
print("PCA Cluster Labels:", pcacluster_labels)


# Create a copy of the DataFrame with the PCA data
pca_df_clustered = pca_df.copy()

# Add a new column to the DataFrame with the predicted clusters
pca_df_clustered['PCA Cluster Labels'] = pcacluster_labels

# Display sample data
display(pca_df_clustered.head(5))


# Create a scatter plot using hvPlot to visualize the clusters formed in the PCA-transformed data
scatter_plot = pca_df_clustered.hvplot.scatter(
    x='PC1',  # Set the x-axis to represent the first principal component (PC1)
    y='PC2',  # Set the y-axis to represent the second principal component (PC2)
    by='PCA Cluster Labels',  # Color the points in the plot according to their assigned PCA cluster labels
    hover_cols=['coin_id'],  # Enable hover functionality to display the coin_id when hovering over points
    title='Cryptocurrency Clusters',  # Set the title of the plot to "Cryptocurrency Clusters"
    height=500,  # Set the height of the plot to 500 pixels
    width=700  # Set the width of the plot to 700 pixels
)

# Display the scatter plot
scatter_plot





# Create a DataFrame to store the feature weights (loadings) for each principal component
pca_components_df = pd.DataFrame(
    data=pca.components_.T,  # Transpose the principal components matrix so that features align with their respective weights
    columns=[f'PC{i+1}' for i in range(pca.n_components_)],  # Name the columns as PC1, PC2, etc., for each principal component
    index=market_data_scaled_df.columns  # Set the index of the DataFrame to the original feature names from the scaled market data
)

# Display the DataFrame to examine the contribution of each feature to the principal components
display(pca_components_df)



